{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 7 Linear Regression with TensorFlow using the California Housing Dataset\n",
    "\n",
    "The goal of this exercise is to implement a linear regression model using TensorFlow to predict house prices based on the California Housing Dataset. The dataset contains various features such as average income, housing average age, and more. Your task is to build a linear regression model and evaluate its performance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the required libraries:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T20:10:31.752843Z",
     "start_time": "2023-07-12T20:10:31.024849Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the California Housing Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n"
     ]
    }
   ],
   "source": [
    "raw = fetch_california_housing()\n",
    "X = pd.DataFrame(data=raw['data'], columns=raw['feature_names'])\n",
    "print(X.head())\n",
    "y = pd.Series(raw['target'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T20:10:41.929594700Z",
     "start_time": "2023-07-12T20:10:37.490248100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess the data:\n",
    "* Normalize the features using the mean and standard deviation.\n",
    "* Split the dataset into training and testing sets (e.g., 80% for training, 20% for testing)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.34476576  0.98214266  0.62855945 -0.15375759 -0.9744286  -0.04959654\n",
      "   1.05254828 -1.32783522]\n",
      " [ 2.33223796 -0.60701891  0.32704136 -0.26333577  0.86143887 -0.09251223\n",
      "   1.04318455 -1.32284391]\n",
      " [ 1.7826994   1.85618152  1.15562047 -0.04901636 -0.82077735 -0.02584253\n",
      "   1.03850269 -1.33282653]\n",
      " [ 0.93296751  1.85618152  0.15696608 -0.04983292 -0.76602806 -0.0503293\n",
      "   1.03850269 -1.33781784]\n",
      " [-0.012881    1.85618152  0.3447108  -0.03290586 -0.75984669 -0.08561576\n",
      "   1.03850269 -1.33781784]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# Note that X is now an ndarray\n",
    "print(X[:5, :])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T20:12:15.621414100Z",
     "start_time": "2023-07-12T20:12:15.587954300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the TensorFlow graph:\n",
    "* Create placeholders for the input features (X) and target variable (y).\n",
    "* Create variables for the model's weights (W) and bias (b).\n",
    "* Define the linear regression model using the equation: y_pred = X * W + b.\n",
    "* Define the loss function as the mean squared error between the predicted values and the true values.\n",
    "* Choose an optimizer (e.g., Gradient Descent) to minimize the loss function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "X_placeholder = tf.compat.v1.placeholder(tf.float32, shape=[None, X_train.shape[1]])\n",
    "y_placeholder = tf.compat.v1.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.compat.v1.random_normal([X_train.shape[1], 1]))\n",
    "b = tf.Variable(tf.compat.v1.random_normal([1]))\n",
    "\n",
    "y_pred = tf.matmul(X_placeholder, W) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_pred - y_placeholder))\n",
    "\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T20:33:18.049701400Z",
     "start_time": "2023-07-12T20:33:17.923704400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the model:\n",
    "* Initialize TensorFlow session.\n",
    "* Initialize the model's variables.\n",
    "* Set the number of training epochs and the learning rate.\n",
    "* For each epoch, iterate through the training dataset and update the model's parameters using the optimizer.\n",
    "* Print the training loss at regular intervals."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Loss = 2.805790662765503\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "\n",
    "with tf.compat.v1.Session() as tfsession:\n",
    "    tfsession.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            batch_X = X_train[i:i+batch_size]\n",
    "            batch_y = y_train[i:i+batch_size]\n",
    "            tfsession.run(train_op, feed_dict={X_placeholder: batch_X, y_placeholder: batch_y})\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            train_loss = tfsession.run(loss, feed_dict={X_placeholder: X_train, y_placeholder: y_train})\n",
    "            print(f\"Epoch {epoch}: Training Loss = {train_loss}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T20:34:08.676814600Z",
     "start_time": "2023-07-12T20:34:06.019399500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the model:\n",
    "* Use the trained model to make predictions on the test dataset.\n",
    "* Calculate the mean squared error (MSE) between the predicted and true values.\n",
    "* Print the MSE as a measure of the model's performance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
